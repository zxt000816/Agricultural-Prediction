{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zyf13\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 123\n"
     ]
    }
   ],
   "source": [
    "import warnings, torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(123)\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer, DeepAR, RecurrentNetwork, GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAPE, NormalDistributionLoss, QuantileLoss, SMAPE\n",
    "\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "from AnalyzeTools.models import autoregressive_integrated_moving_average, linear_regression, support_vector_regression, random_forest, gradient_boosting\n",
    "from AnalyzeTools.prepare import data_split, model_eval, pathForSavingModels, retriveBestModelPath\n",
    "from AnalyzeTools.preprocess import preprocessData\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "params_path = './Models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read data '''\n",
    "raw_file_name = '경략가격집계 - 소,돼지'\n",
    "product = \"pork-hot\"\n",
    "product_attribute = \"경락가격\"\n",
    "\n",
    "_output = 'MAX_COST_AMT' # MIN_COST_AMT\n",
    "default_exclude_cols = ['JUDGE_GUBN', 'JUDGE_BREED', 'JUDGE_SEX', 'SABLE_GUBN', 'ABATT_CODE']\n",
    "\n",
    "df = pd.read_csv('../Data/beef/경략가격집계 - 소,돼지.csv', encoding = 'euc_kr', engine ='python').query(\"JUDGE_KIND == 2\")\n",
    "\n",
    "df = df.drop(default_exclude_cols, axis=1)\n",
    "df = df.groupby(['STD_DATE']).mean().reset_index()\n",
    "df['STD_DATE'] = df['STD_DATE'].apply(lambda x: \"20\" + \"-\".join(x.split(\"/\")))\n",
    "\n",
    "df, _input = preprocessData(df, 'STD_DATE', _output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_split_params = {'Model': 'ML', 'Future': 1}\n",
    "X_train, X_test, y_train, y_test, input_scaler, output_scaler = data_split(df, input_cols=_input, output=_output, train_size=0.8, scaling=True, **ml_split_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_searchCV_params = {\n",
    "    'base_dir': params_path,\n",
    "    'product': product,\n",
    "    'attribute': product_attribute,\n",
    "    'raw': raw_file_name,\n",
    "}\n",
    "\n",
    "model, best_params = support_vector_regression(X_train, y_train, search=True, save=True, **ml_searchCV_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "model_eval(y_test, predictions, stdout=True, vis=True, **{'scaler': output_scaler})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.copy()\n",
    "\n",
    "# data['time_idx'] = range(len(data))\n",
    "# data['group'] = product\n",
    "\n",
    "# training_cutoff = floor(len(data) * 0.8)\n",
    "\n",
    "# max_prediction_length = 1\n",
    "# max_encoder_length = 30 # 7, 14, 30, 60, 120\n",
    "# batch_size = 64\n",
    "\n",
    "# group = ['group']\n",
    "# time_varying_known_categoricals = ['month', 'week']\n",
    "# time_varying_unknown_categoricals = []\n",
    "# time_varying_known_reals = ['time_idx']\n",
    "# time_varying_unknown_reals = _input + [_output]\n",
    "\n",
    "# cell = 'LSTM'\n",
    "# saving_dir = pathForSavingModels(product, product_attribute, raw_file_name, 'LSTM')\n",
    "# best_model_path = retriveBestModelPath(saving_dir)\n",
    "\n",
    "# print(f\"time_varying_known_categoricals: {time_varying_known_categoricals}\")\n",
    "# print(f\"time_varying_unknown_categoricals: {time_varying_unknown_categoricals}\")\n",
    "# print(f\"time_varying_known_reals: {time_varying_known_reals}\")\n",
    "# print(f\"time_varying_unknown_reals: {time_varying_unknown_reals}\")\n",
    "\n",
    "# data[time_varying_known_categoricals] = data[time_varying_known_categoricals].astype(str).astype(\"category\")\n",
    "# training = TimeSeriesDataSet(\n",
    "#     data[lambda x: x.time_idx <= training_cutoff],\n",
    "#     time_idx=\"time_idx\",\n",
    "#     target=_output,\n",
    "#     group_ids=group,\n",
    "#     max_encoder_length=max_encoder_length,\n",
    "#     max_prediction_length=max_prediction_length,\n",
    "#     time_varying_known_categoricals=time_varying_known_categoricals,\n",
    "#     time_varying_unknown_categoricals=time_varying_unknown_categoricals,\n",
    "#     time_varying_known_reals=time_varying_known_reals+[i for i in time_varying_unknown_reals if i != _output],\n",
    "#     time_varying_unknown_reals=[_output],\n",
    "# )\n",
    "\n",
    "# validation = TimeSeriesDataSet.from_dataset(\n",
    "#     training, \n",
    "#     data, \n",
    "#     min_prediction_idx=training.index.time.max() + 1,\n",
    "#     stop_randomization=True\n",
    "# )\n",
    "\n",
    "# train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "# val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)\n",
    "\n",
    "# for x, y in iter(val_dataloader):\n",
    "#     for k in x.keys():\n",
    "#         print(f\"\\n{k}:\\n  {x[k]}\")\n",
    "#     print(f\"\\ny:\\n  {y}\")\n",
    "#     break\n",
    "\n",
    "# if not best_model_path:\n",
    "#     early_stop_callback = EarlyStopping(monitor=\"val_loss\", verbose=False, mode=\"min\")\n",
    "#     lr_logger = LearningRateMonitor()\n",
    "\n",
    "#     trainer = pl.Trainer(\n",
    "#         max_epochs=100,\n",
    "#         gpus=0,\n",
    "#         weights_summary='top',\n",
    "#         callbacks=[lr_logger, early_stop_callback],\n",
    "#         log_every_n_steps=10,\n",
    "#         default_root_dir=saving_dir,\n",
    "#     )\n",
    "\n",
    "#     model = RecurrentNetwork.from_dataset(\n",
    "#         training,\n",
    "#         cell_type=cell,\n",
    "#         hidden_size=128,\n",
    "#         rnn_layers=1,\n",
    "#         dropout=0.1,\n",
    "#         output_size=1,\n",
    "#         loss=MAPE(),\n",
    "#         log_interval=10\n",
    "#     )\n",
    "\n",
    "#     trainer.fit(\n",
    "#         model,\n",
    "#         train_dataloaders=train_dataloader,\n",
    "#         val_dataloaders=val_dataloader\n",
    "#     )\n",
    "\n",
    "# best_model_path = retriveBestModelPath(saving_dir)\n",
    "# best_model = RecurrentNetwork.load_from_checkpoint(best_model_path, cell_type=cell)\n",
    "\n",
    "# actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "# predictions = best_model.predict(val_dataloader)\n",
    "# model_eval(actuals, predictions, stdout=True, vis=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f774c96c8c34c53ecd4c73b34542f198e825b7806220478caf5e39d6877a780"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
