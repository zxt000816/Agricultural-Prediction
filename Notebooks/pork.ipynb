{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zyf13\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "from AnalyzeTools.models import autoregressive_integrated_moving_average, linear_regression, support_vector_regression, random_forest, gradient_boosting, lstm, gru\n",
    "from AnalyzeTools.prepare import data_split, filterSameColumns, model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경략가격집계 - 소,돼지.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read data '''\n",
    "params_path = '../Parameters'\n",
    "raw_file_name = '경략가격집계 - 소,돼지'\n",
    "product = \"pork\"\n",
    "product_attribute = \"경락가격\"\n",
    "\n",
    "_output = 'MAX_COST_AMT' # MIN_COST_AMT\n",
    "default_exclude_cols = ['JUDGE_GUBN', 'JUDGE_BREED', 'JUDGE_SEX', 'SABLE_GUBN', 'ABATT_CODE']\n",
    "\n",
    "df = pd.read_csv('../Data/beef/경략가격집계 - 소,돼지.csv', encoding = 'euc_kr', engine ='python').query(\"JUDGE_KIND == 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT: 10.830940879245123\n",
      "MIN_COST_AMT: 12225.92215065452\n",
      "SUM_COST_AMT: 453.80333127638863\n",
      "SUM_WEIGHT: 22.771022320410545\n",
      "DEFECT_CNT: 10.847147039897516\n",
      "DEFECT_MIN_COST_AMT: 12224.429538051429\n",
      "DEFECT_MAX_COST_AMT: 68115742426.72451\n",
      "DEFECT_SUM_COST_AMT: 453.74541708319583\n",
      "DEFECT_SUM_WEIGHT: 22.79391001099421\n",
      "\n",
      "Input is: ['MIN_COST_AMT', 'SUM_COST_AMT', 'MAX_COST_AMT']\n",
      "Output is: ['MAX_COST_AMT']\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "\n",
    "data = data.drop(default_exclude_cols, axis=1)\n",
    "data = data.groupby(['STD_DATE']).mean().reset_index()\n",
    "\n",
    "''' Preprocess data '''\n",
    "# Delete the column whose correlation to the _output column is NA\n",
    "features = data.corr()[_output].dropna().index.tolist()\n",
    "features.remove(_output)\n",
    "\n",
    "data = data[['STD_DATE'] + features + [_output]]\n",
    "\n",
    "# Delete the first N rows containing the NA value\n",
    "drop_rows = []\n",
    "if data[features].isnull().values.any():\n",
    "    for i, row in data[features].iterrows():\n",
    "        if row.isnull().values.any():\n",
    "            drop_rows.append(i)\n",
    "            continue\n",
    "        break\n",
    "\n",
    "# Fill NA in dataframe\n",
    "if data[features].isnull().values.any():\n",
    "    data = data.interpolate(method='linear', limit_direction='forward')\n",
    "\n",
    "data = data.drop(drop_rows, axis=0)\n",
    "data.index = range(len(data))\n",
    "\n",
    "# Parse date\n",
    "data['STD_DATE'] = data['STD_DATE'].apply(lambda x: \"20\" + \"-\".join(x.split(\"/\")))\n",
    "data['STD_DATE'] = pd.to_datetime(data['STD_DATE'])\n",
    "data['year'] = data['STD_DATE'].dt.year\n",
    "data['month'] = data['STD_DATE'].dt.month\n",
    "data['week'] = data['STD_DATE'].dt.isocalendar().week\n",
    "data['day'] = data['STD_DATE'].dt.day\n",
    "\n",
    "data = data[['STD_DATE', 'year', 'month', 'week', 'day'] + features + [_output]] # Organize data\n",
    "\n",
    "# feature selection\n",
    "K = int(len(features)/2)\n",
    "feature_selector = SelectKBest(score_func=f_regression, k=K)\n",
    "feature_selector.fit_transform(data[features].values, data[_output].values)\n",
    "\n",
    "# print all features scores\n",
    "for k, v in zip(features, feature_selector.scores_):\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "k_best_features = list(np.array(features)[feature_selector.get_support()])\n",
    "\n",
    "# Filter features with almost identical values\n",
    "_input = filterSameColumns(data, k_best_features + [_output])\n",
    "\n",
    "data = data[['STD_DATE', 'year', 'month', 'week', 'day'] + _input + [_output]] # Organize data\n",
    "\n",
    "print(\"\\nInput is: {}\\nOutput is: {}\".format(_input + [_output], [_output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (2037, 4) y_train: (2037,) X_test: (510, 4) y_test: (510,)\n",
      "\n",
      "ARIMA\n",
      "MAPE: 0.1267953273530041 R square: 0.16777411797042452\n",
      "\n",
      "Linear Regression\n",
      "MAPE: 0.045910604122508164 R square: 0.7887015528605147\n",
      "\n",
      "Support Vector Regression\n",
      "MAPE: 0.13013485895283466 R square: -0.0283453544534924\n",
      "\n",
      "Random Forest\n",
      "MAPE: 0.053341627870593246 R square: 0.733348560155897\n",
      "\n",
      "Gradient Boosting\n",
      "MAPE: 0.05635219573126297 R square: 0.6885893101210536\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset for ML or DL\n",
    "ml_split_params = {'Model': 'ML', 'Future': 1}\n",
    "X_train, X_test, y_train, y_test = data_split(data, input_cols=_input, output=_output, train_size=0.8, **ml_split_params)\n",
    "\n",
    "''' Input data into models and Evaluate model results '''\n",
    "ml_searchCV_params = {\n",
    "    'base_dir': params_path,\n",
    "    'product': product,\n",
    "    'attribute': product_attribute,\n",
    "    'raw': raw_file_name,\n",
    "    'save': True\n",
    "}\n",
    "stdout = True\n",
    "vis = False\n",
    "\n",
    "print(\"\\nARIMA\")\n",
    "arima = autoregressive_integrated_moving_average(y_train)\n",
    "model_eval(y_test, arima.predict(n_periods=len(y_test), return_conf_int=False, aplha=0.05), stdout=stdout, vis=vis)\n",
    "\n",
    "print(\"\\nLinear Regression\")\n",
    "lr, _ = linear_regression(X_train, y_train)\n",
    "model_eval(y_test, lr.predict(X_test), stdout=stdout, vis=vis)\n",
    "\n",
    "print(\"\\nSupport Vector Regression\")\n",
    "svr, _ = support_vector_regression(X_train, y_train, search=True, **ml_searchCV_params)\n",
    "model_eval(y_test, svr.predict(X_test), stdout=stdout, vis=vis)\n",
    "\n",
    "print(\"\\nRandom Forest\")\n",
    "rf, _ = random_forest(X_train, y_train, search=True, **ml_searchCV_params)\n",
    "model_eval(y_test, rf.predict(X_test), stdout=stdout, vis=vis)\n",
    "\n",
    "print(\"\\nGradient Boosting\")\n",
    "gb, _ = gradient_boosting(X_train, y_train, search=True, **ml_searchCV_params)\n",
    "model_eval(y_test, gb.predict(X_test), stdout=stdout, vis=vis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f774c96c8c34c53ecd4c73b34542f198e825b7806220478caf5e39d6877a780"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
